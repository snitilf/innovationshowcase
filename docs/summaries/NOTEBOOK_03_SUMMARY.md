# Comprehensive Summary: Dataset Expansion for Machine Learning Model Training

## Introduction and Purpose

This analysis expands the baseline dataset from 3 countries to 19 countries, increasing observations from 42 to 266 country-year observations. This expansion addresses a critical technical limitation: machine learning models require substantial amounts of data to learn reliable, generalizable patterns. With only 42 observations, a model would overfit to the specific patterns of three countries rather than learning patterns applicable to new countries.

The expansion serves three technical objectives: (1) providing sufficient sample size for model training (266 observations meets the threshold for training a decision tree classifier), (2) introducing diversity in governance patterns across different institutional contexts, and (3) maintaining the validation framework with documented corruption cases (Malaysia, Mozambique) and control countries (Canada and others).

## Country Selection Strategy

The expansion adds 16 countries to the original 3-country baseline, selected through a strategic approach that ensures diverse governance patterns while maintaining analytical coherence. The selection strategy recognizes that corruption risk assessment requires understanding how governance indicators behave across different institutional contexts, economic development levels, and geographic regions.

### Baseline Countries (Preserved from Previous Analysis)

The three original countries are retained to maintain continuity with previous analysis and preserve the validation framework:

**Canada** continues to serve as a control case with strong governance institutions and no documented major corruption scandals during the study period. Canada's consistently high governance scores across all dimensions provide a baseline for what protective governance looks like.

**Malaysia** represents a middle-income country with a documented major corruption scandal (the 1MDB scandal involving $4.5 billion USD stolen from a state development fund). Malaysia's moderate governance scores demonstrate that corruption can occur even in countries with some functional governance institutions, not just in countries with the weakest institutions.

**Mozambique** represents a lower-income country with a documented corruption case (the hidden debt crisis involving $2 billion USD in illicit loans). Mozambique's consistently weak governance scores demonstrate how structural vulnerabilities enable large-scale corruption in development contexts.

### Additional Countries: Diverse Governance Patterns

The 16 additional countries are selected to represent diverse governance patterns across multiple dimensions:

**High-Risk Countries** (countries with documented governance weaknesses or corruption vulnerabilities): Angola, Venezuela, Zimbabwe, Iraq, Ukraine. These countries are selected because they demonstrate governance patterns similar to countries with documented corruption cases, providing additional examples of high-risk environments. They help the model learn patterns associated with weak institutions, limited accountability, and structural vulnerabilities that enable corruption.

**Medium-Risk Countries** (countries with mixed governance profiles): Brazil, South Africa, India, Philippines. These countries are selected because they demonstrate moderate governance scores that sometimes fall below thresholds for corruption risk, providing examples of environments where governance quality is mixed rather than consistently strong or consistently weak. They help the model learn to distinguish between moderate-risk and high-risk environments.

**Low-Risk Control Countries** (countries with strong governance institutions): Norway, Denmark, Singapore, Australia, New Zealand, Switzerland, Germany. These countries are selected because they demonstrate consistently strong governance scores across multiple dimensions, providing additional examples of protective governance that prevents corruption. They help the model learn patterns associated with strong institutions, effective accountability mechanisms, and structural conditions that prevent corruption.

The selection strategy ensures that the expanded dataset spans the full spectrum of governance quality, from countries with the weakest institutions to countries with the strongest institutions. This diversity is essential for machine learning model training because the model must learn to distinguish between high-risk and low-risk environments across different contexts, not just for the specific three countries in the baseline dataset.

## Data Collection and Quality Assessment

The data collection process follows the same methodology as the baseline analysis, retrieving six governance indicators and five economic indicators for all 19 countries across 2010-2023 using the World Bank API. The expanded dataset maintains consistency with the baseline to ensure uniform application of the labeling methodology.

### Data Completeness Results

**Governance Indicators**: All six Worldwide Governance Indicators show 100% completeness across all 19 countries and all years (266 observations). This complete coverage is essential for the labeling methodology, which requires all six indicators to calculate threshold-based flags.

**Economic Indicators**: Variable completeness reflects country-specific reporting differences. External Debt shows 52.2% missing data (primarily due to inconsistent reporting), Poverty Headcount Ratio shows 57.1% missing data (poverty surveys are not conducted annually), Government Expenditure shows 18.3% missing data, while GDP Growth and Foreign Direct Investment show low missing data (~4%). These missing values do not affect risk labeling, which depends solely on governance indicators. Economic indicators will be handled through imputation strategies during model training.

## Labeling Methodology Application

The same threshold-based labeling methodology from the previous phase is applied uniformly across all 19 countries. The methodology creates binary flags for each of six governance indicators when scores fall below established thresholds: Voice and Accountability (1.15), Political Stability (0.50), Government Effectiveness (1.15), Regulatory Quality (1.15), Rule of Law (1.15), and Control of Corruption (1.15). A country-year observation is labeled as high-risk (1) if it receives 4 or more flags; otherwise, it is labeled as low-risk (0).

## Validation Results

The labeling methodology maintains perfect validation when applied to the expanded dataset: Malaysia's 1MDB period (2013-2015) correctly labeled as high-risk (3/3 years), Mozambique's hidden debt crisis (2013-2016) correctly labeled as high-risk (4/4 years), and Canada's control case correctly labeled as low-risk throughout (0/14 high-risk years). These results confirm that the methodology remains accurate when scaled to a larger, more diverse dataset.

## Key Findings and Patterns

The expanded dataset reveals important patterns in governance quality and corruption risk labels that provide insights into the relationship between institutional quality and corruption vulnerability across diverse contexts.

### Overall Label Distribution

The final labeled dataset contains 266 country-year observations (19 countries Ã— 14 years, with some countries having complete data for all years). Of these observations, 112 (42.1%) are classified as low-risk and 154 (57.9%) are classified as high-risk. This distribution reflects that the expanded dataset includes substantial representation of both high-risk and low-risk environments, providing balanced data for machine learning model training.

The high proportion of high-risk labels (57.9%) is expected given the country selection strategy, which intentionally included countries with documented corruption cases and countries with governance weaknesses. However, the substantial representation of low-risk labels (42.1%) ensures that the model learns patterns associated with both high-risk and low-risk environments, enabling reliable classification.

### Governance Patterns Across Risk Categories

Analysis of governance scores across risk categories reveals clear separation: high-risk countries show consistently low scores below thresholds across all dimensions, medium-risk countries show mixed profiles, and low-risk countries show consistently high scores above thresholds. This separation validates that the threshold-based approach captures meaningful distinctions in institutional quality.

### Temporal Patterns and Stability

The analysis reveals important temporal patterns in risk labels across countries. Some countries show consistent risk labels throughout the study period (for example, Canada consistently shows low-risk labels, while Mozambique consistently shows high-risk labels), reflecting stable governance institutions. Other countries show variation in risk labels across years (for example, Malaysia shows both low-risk and high-risk labels at different times), reflecting changes in governance quality over time.

These temporal patterns are important for machine learning model training because they enable the model to learn both stable patterns (countries that consistently show high-risk or low-risk) and dynamic patterns (countries that transition between risk categories). This diversity helps the model learn generalizable patterns that can be applied to new countries and time periods.

### Country-Specific Risk Profiles

The expanded dataset reveals distinct risk profiles: countries with documented corruption (Malaysia, Mozambique) show high-risk labels during corruption periods; countries with strong governance (Canada, Norway, Denmark, Switzerland, Germany, Australia, New Zealand, Singapore) show consistently low-risk labels; and countries with governance weaknesses but no documented corruption (Angola, Venezuela, Zimbabwe, Iraq, Ukraine) show consistently high-risk labels, suggesting governance indicators can signal vulnerability before corruption is exposed.

## Technical Contributions

### Dataset Scale and Machine Learning Suitability

The expansion from 42 to 266 observations addresses the critical requirement for machine learning model training. With only 42 observations, models would overfit to three countries' specific patterns. The 266 observations provide sufficient sample size for training a decision tree classifier while maintaining generalizability. The balanced class distribution (57.9% high-risk, 42.1% low-risk) prevents class imbalance issues that could compromise model performance.

### Diversity and Generalization

The inclusion of 19 countries spanning the full spectrum of governance quality (from Iraq's weak institutions to Norway's strong institutions) ensures the model learns generalizable patterns rather than country-specific memorization. This diversity helps prevent overfitting by forcing the model to learn broadly applicable patterns across different institutional contexts, economic development levels, and geographic regions.

### Validation Across Diverse Contexts

Perfect validation results in the expanded dataset confirm the methodology's robustness: the threshold-based approach works consistently across countries with different governance profiles, not just the original three countries. This supports using the methodology for risk assessment in new countries and time periods.

### Dataset Structure for Model Training

The final dataset contains 266 country-year observations with 23 variables: 6 governance indicators, 5 economic indicators, 6 binary flags, total flag count, risk category classification, and the corruption risk label (target variable). This structure provides both predictive features and the target variable needed for supervised machine learning model training.

## Visualization and Pattern Discovery

The analysis creates three key visualizations: (1) governance indicators by risk category showing clear separation between high-risk, medium-risk, and low-risk countries; (2) a heatmap of average governance scores by country sorted by Control of Corruption, revealing the full spectrum of governance quality across 19 countries; and (3) a heatmap of corruption risk labels by country and year, showing temporal patterns including stable risk labels (Canada, Mozambique) and variable patterns (Malaysia). These visualizations provide visual validation that the labeling methodology captures meaningful distinctions in institutional quality.

## Dataset Export

The final dataset is exported as `corruption_data_expanded_labeled.csv` containing 266 country-year observations with 23 variables: 6 governance indicators, 5 economic indicators, 6 binary flags, total flag count, risk category classification, and the corruption risk label (target variable). This dataset provides the foundation for machine learning model training with both predictive features and the target variable.

## Conclusion

This dataset expansion successfully transforms the baseline 3-country dataset into a 19-country dataset with 266 observations suitable for machine learning model training. The key technical contributions are: (1) sufficient sample size (266 observations) for training a decision tree classifier, (2) diversity across the full spectrum of governance quality preventing overfitting, and (3) perfect validation results confirming methodology robustness across diverse contexts.

The expanded dataset provides the essential foundation for subsequent machine learning model development, with both predictive features (governance and economic indicators) and the target variable (corruption risk labels) needed for supervised learning. The balanced class distribution and diverse country representation ensure the model will learn generalizable patterns that can identify high-risk environments before corruption occurs, supporting the Global Trust Engine's development as a data-driven early warning system for corruption risk in development contexts.

