# Summary: Decision Tree Training and Model Evaluation

## Introduction and Purpose

This analysis represents the final phase of the Global Trust Engine development: training and evaluating a machine learning model to test whether economic indicators and sentiment analysis can serve as leading indicators that signal corruption risk before governance metrics reflect institutional weaknesses. The model uses a Decision Tree Classifier to predict governance-based corruption risk labels using only economic indicators and sentiment scores, creating a rigorous test that avoids circular reasoning by separating the features used to create labels (governance indicators) from the features used to make predictions (economic and sentiment indicators).

## Model Training Approach

The Decision Tree Classifier was selected for its interpretability, providing a transparent flowchart of decision-making rules that stakeholders can understand and trust. The algorithm uses gini impurity as the splitting criterion, which measures how mixed the classes are within a group. Think of it like sorting a bag of mixed fruits: gini = 0 means all apples in one bag and all oranges in another (perfectly separated), while gini = 0.5 means half apples and half oranges in the same bag (completely mixed). At each node, the algorithm selects the feature and threshold that minimizes gini impurity, creating the purest groups possible.

For example, splitting by "Poverty > 20%" might separate 80 countries (75 high-risk, 5 low-risk) from 20 countries (all low-risk), creating a good split. In contrast, splitting by "GDP Growth > 3%" might result in both groups having equal numbers of high-risk and low-risk countries, which doesn't help predict corruption risk. The decision tree automatically finds the best splits that create the most pure groups.

The model was trained on 212 country-year observations (80% of the dataset) with the following parameters: max_depth=5 (limits tree depth for interpretability), min_samples_split=10 and min_samples_leaf=5 (prevent overfitting by requiring minimum samples), class_weight='balanced' (handles class imbalance), and random_state=42 (ensures reproducibility). The remaining 54 observations (20% of the dataset) were reserved for testing, enabling evaluation on unseen data to assess generalizability. Starting from the root, the algorithm recursively splits the data by finding the feature and threshold that best separates high-risk from low-risk cases, building a tree up to 5 levels deep.

## Model Performance Results

The trained model achieves strong performance across all key metrics, demonstrating successful prediction of governance-based risk labels using only economic and sentiment indicators. Model evaluation was conducted on a held-out test set of 54 country-year observations that were not used during training, ensuring that performance metrics reflect the model's ability to generalize to unseen data rather than memorizing training patterns.

On the test set, the model achieves 94.4% accuracy, meaning it correctly classifies 94.4% of all predictions. Precision reaches 96.7%, indicating that when the model predicts high-risk, it is correct 96.7% of the time. Recall reaches 93.6%, meaning the model correctly identifies 93.6% of all actual high-risk cases. The F1-score, which balances precision and recall, reaches 95.1%. The ROC-AUC score, which measures overall discriminative ability between high-risk and low-risk cases, reaches 95.9%.

These metrics are critical for an early warning system. Accuracy measures overall prediction correctness—the proportion of all predictions that are correct. Precision measures how reliable high-risk predictions are—of predicted high-risk cases, how many are actually high-risk. Recall measures the proportion of actual high-risk cases correctly identified—critical for early warning, as missing a high-risk case could lead to corruption scandals. The F1-score balances both precision and recall, providing a single metric that considers both concerns. The ROC-AUC score measures overall discriminative ability between high-risk and low-risk cases across all possible classification thresholds.

Recall is particularly critical for an early warning system, as it measures the proportion of actual high-risk cases correctly identified. A high recall rate (93.6%) ensures that the model captures most high-risk environments, enabling proactive intervention before corruption scandals occur. The strong performance across all metrics demonstrates that economic indicators can successfully predict governance-based labels, validating the leading indicator hypothesis.

## Feature Discovery: The Three Core Indicators

The decision tree automatically discovered that only three out of six predictive features are needed to achieve 94.4% accuracy. The model identified three core economic indicators as the primary predictors of corruption risk: poverty levels (41.8% importance), external debt burden (33.0% importance), and government spending patterns (25.1% importance). These three indicators capture the economic conditions that deteriorate before governance metrics reflect institutional weaknesses, supporting the leading indicator hypothesis.

The hierarchical importance structure reveals that poverty is the single most important predictor, appearing at the root node of the decision tree. This means poverty rates alone can distinguish between high-risk and low-risk cases more effectively than any other single indicator. External debt appears at the second level of the tree, followed by government spending at deeper levels, confirming that these three indicators work together, with poverty providing the initial separation and debt and spending providing refinements.

The model determined that the other three features—GDP growth, foreign direct investment inflows, and sentiment scores—do not improve predictions beyond what the three core indicators already provide. GDP growth overlaps with poverty rates (countries with high poverty typically have lower or more volatile growth). Foreign direct investment overlaps with debt patterns (countries with high debt often have low foreign investment). Sentiment scores revealed important insights about transparency and media suppression, but the complex relationship makes sentiment less reliable as a standalone predictive feature compared to the direct economic indicators.

This feature reduction is a positive finding: the model identified that three core economic indicators are sufficient to predict corruption risk, making the model simpler and more interpretable while maintaining high accuracy. The automatic feature selection demonstrates that the model learned meaningful patterns rather than memorizing noise, and the simplicity enhances practical utility for policymakers who need to monitor only three key indicators. The fact that the model uses only three features throughout all its splits confirms that GDP growth, FDI inflows, and sentiment scores are not needed, making the decision process transparent and understandable.

## Interpretability and Decision Tree Visualization

The decision tree visualization provides a complete visual representation of how the model makes predictions, creating a transparent flowchart that enables stakeholders to understand and trust the model's decision-making process. Each box in the tree represents a decision point or final prediction, showing the specific feature being evaluated, the threshold value, the gini impurity score (measuring class separation), the sample count, the class distribution, and the predicted class.

Starting from the top (root node), the tree asks a series of yes/no questions about the economic indicators. Each answer leads to the next question, creating a path through the tree until reaching a leaf node (a box at the bottom with no further splits), which provides the final prediction. The tree structure reveals feature importance (features near the top are more important), decision thresholds (exact economic conditions where risk changes), and progressive refinement (gini scores decrease as we move down the tree, creating purer groups).

For example, a typical path might be: Is poverty rate above a certain threshold? If yes, go left; if no, go right. Is external debt above a certain threshold? Continue based on the answer. Is government spending above a certain threshold? Continue based on the answer. Reach a final prediction (leaf node). The specific threshold values show exactly where the model draws the line between high-risk and low-risk, providing clear, actionable criteria for risk assessment.

This transparency is essential for an early warning system designed for development integrity. Unlike black-box models, every prediction can be traced through the tree, enabling stakeholders to see exactly which economic conditions led to a high-risk or low-risk classification. The interpretability builds trust and enables policymakers to understand the model's reasoning, making it suitable for real-world deployment in development contexts. By monitoring these specific thresholds, policymakers can identify countries approaching high-risk conditions before governance metrics reflect institutional weaknesses.

## Validation of Leading Indicator Hypothesis

The model's successful performance validates the core research hypothesis: economic indicators can serve as leading indicators that signal corruption risk before governance metrics reflect institutional weaknesses. By predicting governance-based risk labels using only economic indicators, the model demonstrates that economic conditions deteriorate before governance metrics capture institutional failures, enabling proactive intervention before corruption scandals occur.

The separation of labeling features (governance indicators) from predictive features (economic and sentiment indicators) creates a rigorous test that avoids circular reasoning. If the model had used governance indicators as predictive features, it would simply memorize the labeling rule rather than discover whether other indicators can predict corruption risk. Instead, the model must learn meaningful patterns from economic conditions to predict governance-based labels, creating a genuine test of the leading indicator hypothesis.

The strong performance (94.4% accuracy, 93.6% recall) demonstrates that measurable economic indicators can reliably signal early signs of financial and political vulnerability. The three core indicators—poverty, external debt, and government spending—capture the economic conditions that signal vulnerability to corruption, supporting the hypothesis that these measures function as early warning signs. This finding has significant implications for development integrity, as it enables identification of high-risk environments before governance metrics reflect institutional weaknesses, creating opportunities for proactive safeguards.

The temporal relationship between economic conditions and governance deterioration aligns with theoretical frameworks that describe corruption as both a cause and consequence of economic vulnerability. Countries experiencing high poverty rates face increased pressure on limited resources, creating incentives for corruption. Excessive external debt burdens create fiscal stress that weakens institutional oversight. Problematic government spending patterns may reflect diversion of resources away from growth-promoting areas. These economic conditions create environments where corruption can thrive, and the model successfully identifies these patterns before governance metrics reflect the resulting institutional weaknesses.

## Conclusion and Implications

The Decision Tree Classifier successfully predicts corruption risk using economic indicators as leading indicators that deteriorate before governance metrics reflect institutional weaknesses. The model achieves high accuracy and recall, enabling proactive identification of high-risk environments before corruption scandals occur. The automatic discovery of three core economic indicators (poverty, external debt, government spending) demonstrates that these measures are sufficient to predict corruption risk, making the model simpler and more interpretable while maintaining strong performance.

The decision tree's interpretability provides transparent decision-making rules that stakeholders can understand and trust, essential for an early warning system designed for development integrity. By using economic indicators to predict governance-based labels, the model tests whether these measures can function as leading indicators, avoiding circular reasoning while maintaining predictive power. The trained model demonstrates that measurable economic indicators can reliably signal early signs of financial and political vulnerability, underscoring its potential as a proactive policy tool for identifying high-risk environments and developing safeguards to combat corruption.

The findings confirm that economic conditions can serve as early warning signals that precede institutional deterioration. Countries experiencing high poverty rates, excessive external debt burdens, or problematic government spending patterns are more likely to develop corruption vulnerabilities, even before governance metrics reflect these weaknesses. This temporal relationship enables proactive intervention, allowing development institutions to identify high-risk environments and implement safeguards before corruption scandals occur. The model's simplicity—requiring only three economic indicators—enhances practical utility, as policymakers can monitor these measures to assess corruption risk in real-time.

The Global Trust Engine represents a data-driven approach to development integrity, combining quantitative economic indicators with transparent machine learning to create an early warning system. The model's strong performance and interpretability make it suitable for deployment in development contexts, where stakeholders require both accuracy and transparency to trust automated risk assessment systems. By identifying high-risk environments before corruption occurs, the model enables proactive policy interventions that can prevent the diversion of development funds and protect vulnerable populations from the consequences of institutional failure.

The model addresses a critical gap in development integrity: traditional methods rely on governance indicators that reflect conditions after institutional weaknesses have already emerged. By using economic indicators that deteriorate before governance metrics capture institutional failures, the model enables early identification of high-risk environments. This temporal advantage creates opportunities for proactive safeguards, such as enhanced monitoring, conditional aid disbursement, or targeted capacity-building programs. The model's interpretability ensures that these interventions are based on transparent, understandable criteria rather than opaque algorithmic decisions.

The technical contribution of this analysis lies in the rigorous separation of labeling features from predictive features, creating a genuine test of the leading indicator hypothesis. The model's success demonstrates that economic conditions can predict governance-based risk labels, validating the core research question. The automatic feature selection that identified three core indicators demonstrates the model's ability to learn meaningful patterns while maintaining simplicity and interpretability. These findings establish a foundation for data-driven early warning systems in development contexts, where transparency and accuracy are both essential for building trust and enabling effective policy interventions.

