{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Expand Dataset with Additional Countries\n",
        "## Data collection for expanded training dataset\n",
        "\n",
        "Goal: collect world bank data for additional countries to expand from 3 countries (42 rows) to ~15-17 countries (~200+ rows)\n",
        "\n",
        "Countries to add:\n",
        "- High-risk (5): Angola, Venezuela, Zimbabwe, Iraq, Ukraine\n",
        "- Medium-risk (4): Brazil, South Africa, India, Philippines  \n",
        "- Low-risk (7): Norway, Denmark, Singapore, Australia, New Zealand, Switzerland, Germany\n",
        "\n",
        "Timeframe: 2010-2023 (same as baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import wbdata\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "# set working directory to project root\n",
        "# if running from notebooks/, go up one level; otherwise assume already at root\n",
        "current_dir = os.getcwd()\n",
        "if current_dir.endswith('notebooks'):\n",
        "    os.chdir('..')\n",
        "elif 'notebooks' in current_dir:\n",
        "    # if notebooks is in the path, go to project root\n",
        "    project_root = current_dir.split('notebooks')[0].rstrip('/')\n",
        "    if os.path.exists(project_root):\n",
        "        os.chdir(project_root)\n",
        "\n",
        "# verify we're in the right place\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"Data file exists: {os.path.exists('data/raw/corruption_data_baseline.csv')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up country lists by risk category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# original baseline countries (already have data)\n",
        "baseline_countries = {\n",
        "    'CAN': 'Canada',  # low-risk control\n",
        "    'MYS': 'Malaysia',  # high-risk (1MDB)\n",
        "    'MOZ': 'Mozambique'  # high-risk (hidden debt)\n",
        "}\n",
        "\n",
        "# high-risk countries: known corruption scandals, weak governance\n",
        "high_risk_countries = {\n",
        "    'AGO': 'Angola',  # oil revenue corruption\n",
        "    'VEN': 'Venezuela',  # PDVSA corruption, collapsing governance\n",
        "    'ZWE': 'Zimbabwe',  # infrastructure project corruption\n",
        "    'IRQ': 'Iraq',  # reconstruction fund corruption\n",
        "    'UKR': 'Ukraine'  # pre-2014 development fund issues\n",
        "}\n",
        "\n",
        "# medium-risk countries: mixed governance scores, isolated incidents\n",
        "medium_risk_countries = {\n",
        "    'BRA': 'Brazil',  # lava jato but stronger institutions\n",
        "    'ZAF': 'South Africa',  # state capture but decent baseline\n",
        "    'IND': 'India',  # mixed governance, large economy\n",
        "    'PHL': 'Philippines'  # variable governance scores\n",
        "}\n",
        "\n",
        "# low-risk countries: stable, high-governance\n",
        "low_risk_countries = {\n",
        "    'NOR': 'Norway',  # consistently top scores\n",
        "    'DNK': 'Denmark',  # strong anti-corruption\n",
        "    'SGP': 'Singapore',  # high effectiveness and rule of law\n",
        "    'AUS': 'Australia',  # stable governance\n",
        "    'NZL': 'New Zealand',  # clean governance record\n",
        "    'CHE': 'Switzerland',  # strong institutions\n",
        "    'DEU': 'Germany'  # solid governance throughout period\n",
        "}\n",
        "\n",
        "# combine all new countries (excluding baseline)\n",
        "all_new_countries = {**high_risk_countries, **medium_risk_countries, **low_risk_countries}\n",
        "\n",
        "print(f\"baseline countries: {len(baseline_countries)}\")\n",
        "print(f\"high-risk countries: {len(high_risk_countries)}\")\n",
        "print(f\"medium-risk countries: {len(medium_risk_countries)}\")\n",
        "print(f\"low-risk countries: {len(low_risk_countries)}\")\n",
        "print(f\"total new countries: {len(all_new_countries)}\")\n",
        "print(f\"\\nnew country codes: {list(all_new_countries.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining indicators (same as baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# defining all indicators we want to pull\n",
        "# same as baseline notebook - split into governance indicators (main focus) and economic indicators (context)\n",
        "\n",
        "indicators = {\n",
        "    # governance indicators - these match table 1 from morgan's case study\n",
        "    'VA.EST': 'Voice_Accountability',\n",
        "    'PV.EST': 'Political_Stability',\n",
        "    'GE.EST': 'Government_Effectiveness',\n",
        "    'RQ.EST': 'Regulatory_Quality',\n",
        "    'RL.EST': 'Rule_of_Law',\n",
        "    'CC.EST': 'Control_of_Corruption',\n",
        "    \n",
        "    # economic indicators - useful for detecting financial patterns\n",
        "    'DT.DOD.DECT.GN.ZS': 'External_Debt_perc_GNI',\n",
        "    'NY.GDP.MKTP.KD.ZG': 'GDP_Growth_annual_perc',\n",
        "    'GC.XPN.TOTL.GD.ZS': 'Govt_Expenditure_perc_GDP',\n",
        "    'BX.KLT.DINV.WD.GD.ZS': 'FDI_Inflows_perc_GDP',\n",
        "    'SI.POV.DDAY': 'Poverty_Headcount_Ratio'\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading baseline data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the baseline data\n",
        "df_baseline = pd.read_csv('data/raw/corruption_data_baseline.csv')\n",
        "\n",
        "print(f\"baseline dataset shape: {df_baseline.shape[0]} rows, {df_baseline.shape[1]} columns\")\n",
        "print(f\"baseline countries: {df_baseline['Country'].unique()}\")\n",
        "print(f\"baseline years: {df_baseline['Year'].min()} to {df_baseline['Year'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetching data from world bank api for new countries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# date range for historical data\n",
        "data_range = (datetime.datetime(2010, 1, 1), datetime.datetime(2024, 1, 1))\n",
        "\n",
        "# get country codes for new countries\n",
        "new_country_codes = list(all_new_countries.keys())\n",
        "\n",
        "# fetching data from api\n",
        "# get_dataframe pulls all indicators for specified countries and dates\n",
        "df_new = wbdata.get_dataframe(indicators, \n",
        "                              country=new_country_codes, \n",
        "                              date=data_range,\n",
        "                              parse_dates=False)  # keep dates as year strings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning and formatting the dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# reset index so country and date become regular columns\n",
        "df_new = df_new.reset_index()\n",
        "df_new = df_new.rename(columns={'date': 'Year', 'country': 'Country'})\n",
        "\n",
        "# reorder columns for readability\n",
        "column_order = ['Country', 'Year'] + list(indicators.values())\n",
        "existing_columns = [col for col in column_order if col in df_new.columns]\n",
        "df_new = df_new[existing_columns]\n",
        "\n",
        "# sort by country then year\n",
        "df_new = df_new.sort_values(by=['Country', 'Year']).reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspecting the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"shape: {df_new.shape[0]} rows, {df_new.shape[1]} columns\")\n",
        "print(f\"years covered: {df_new['Year'].min()} to {df_new['Year'].max()}\")\n",
        "print(f\"\\ncountries in new data:\")\n",
        "print(df_new['Country'].unique())\n",
        "\n",
        "# checking for missing values\n",
        "print(\"\\nmissing values per column:\")\n",
        "print(df_new.isnull().sum())\n",
        "print(f\"\\nmissing data percentage:\")\n",
        "print(round(df_new.isnull().sum() / len(df_new) * 100, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combining with baseline data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combine baseline and new data\n",
        "# ensure same columns\n",
        "common_columns = list(set(df_baseline.columns) & set(df_new.columns))\n",
        "df_baseline_subset = df_baseline[common_columns]\n",
        "df_new_subset = df_new[common_columns]\n",
        "\n",
        "# combine\n",
        "df_expanded = pd.concat([df_baseline_subset, df_new_subset], ignore_index=True)\n",
        "\n",
        "# sort by country then year\n",
        "df_expanded = df_expanded.sort_values(by=['Country', 'Year']).reset_index(drop=True)\n",
        "\n",
        "print(f\"combined dataset shape: {df_expanded.shape[0]} rows, {df_expanded.shape[1]} columns\")\n",
        "print(f\"total countries: {df_expanded['Country'].nunique()}\")\n",
        "print(f\"\\ncountries in expanded dataset:\")\n",
        "print(sorted(df_expanded['Country'].unique()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving to data/raw/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create directory if it doesn't exist\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "\n",
        "# save the expanded dataset\n",
        "output_path = 'data/raw/corruption_data_expanded.csv'\n",
        "df_expanded.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick analysis of governance indicators\n",
        "\n",
        "checking how new countries compare across the six governance indicators\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtering to just governance indicators\n",
        "governance_cols = ['Country', 'Year', 'Voice_Accountability', 'Political_Stability', \n",
        "                   'Government_Effectiveness', 'Regulatory_Quality', 'Rule_of_Law', \n",
        "                   'Control_of_Corruption']\n",
        "\n",
        "gov_df = df_expanded[governance_cols]\n",
        "\n",
        "# calculate average scores by country\n",
        "print(\"average governance scores by country (2010-2023):\")\n",
        "print(gov_df.groupby('Country')[governance_cols[2:]].mean().round(2))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
