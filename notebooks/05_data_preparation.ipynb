{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Model Training\n",
    "\n",
    "**Goal**: Combine all collected features from notebooks 01-04 into a single, clean dataset ready for machine learning model training.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook prepares the final dataset by combining three distinct data sources, each contributing different information about corruption risk:\n",
    "\n",
    "1. **Governance Indicators (6 features)** - PRIMARY QUANTITATIVE SIGNAL\n",
    "   - World Bank's World Governance Indicators that directly measure institutional quality\n",
    "   - As stated in the theoretical framework: \"measurable governance indicators can reliably signal early signs of financial and political vulnerability\"\n",
    "   - Used to create the corruption_risk labels using the \"4-of-6\" flag system\n",
    "   - Complete coverage: 19 countries, 2010-2023, 266 country-years\n",
    "\n",
    "2. **Economic Indicators (5 features)** - SECONDARY QUANTITATIVE SIGNAL\n",
    "   - Economic context from World Bank API (GDP growth, debt, trade, etc.)\n",
    "   - Provides complementary quantitative information about economic conditions\n",
    "   - Some missing values require imputation\n",
    "\n",
    "3. **Sentiment Analysis (1 feature)** - QUALITATIVE EARLY WARNING SIGNAL\n",
    "   - News sentiment scores from Guardian (2010-2016) and GDELT (2017-2023) APIs\n",
    "   - As outlined in the theoretical framework: \"qualitative data to enrich the model's predictive power\" and serve as an \"early qualitative warning sign alongside quantitative governance indicators\"\n",
    "   - Validated in notebook 04: captures corruption-related news and transparency patterns\n",
    "   - Provides complementary qualitative signal about corruption visibility and public/media perception\n",
    "\n",
    "**Total Features**: 12 (6 governance + 5 economic + 1 sentiment)  \n",
    "**Target Variable**: corruption_risk (binary 0/1, based on governance indicators)  \n",
    "**Output**: Prepared datasets for model training with stratified train/test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/_s3wzh8j3mbgc971jkb0__nc0000gn/T/ipykernel_12498/1760846591.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/snitil/Documents/innovationshowcase\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# set working directory to project root\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "elif 'notebooks' in current_dir:\n",
    "    project_root = current_dir.split('notebooks')[0].rstrip('/')\n",
    "    if os.path.exists(project_root):\n",
    "        os.chdir(project_root)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Governance Indicators (Primary Quantitative Signal)\n",
    "\n",
    "The 6 governance indicators from the World Bank are the **primary quantitative signal** for corruption risk. As stated in the theoretical framework, \"measurable governance indicators can reliably signal early signs of financial and political vulnerability.\" These indicators directly measure institutional quality and are used to create the corruption_risk labels. Countries with poor governance (4 or more indicators below threshold) are labeled as high-risk.\n",
    "\n",
    "### 2.1: Load and Verify Governance Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset shape: (266, 22)\n",
      "Countries: 19\n",
      "Years: 2010 to 2023\n",
      "Total country-years: 266\n",
      "\n",
      "6 Governance Indicators:\n",
      "  1. Voice_Accountability\n",
      "  2. Political_Stability\n",
      "  3. Government_Effectiveness\n",
      "  4. Regulatory_Quality\n",
      "  5. Rule_of_Law\n",
      "  6. Control_of_Corruption\n",
      "\n",
      "✓ all 6 governance indicators present\n"
     ]
    }
   ],
   "source": [
    "# load main dataset with governance and economic indicators\n",
    "main_df = pd.read_csv('data/processed/corruption_data_expanded_labeled.csv')\n",
    "\n",
    "print(f\"Main dataset shape: {main_df.shape}\")\n",
    "print(f\"Countries: {main_df['Country'].nunique()}\")\n",
    "print(f\"Years: {main_df['Year'].min()} to {main_df['Year'].max()}\")\n",
    "print(f\"Total country-years: {len(main_df)}\")\n",
    "\n",
    "# identify the 6 governance indicators\n",
    "governance_cols = [\n",
    "    'Voice_Accountability', 'Political_Stability', 'Government_Effectiveness',\n",
    "    'Regulatory_Quality', 'Rule_of_Law', 'Control_of_Corruption'\n",
    "]\n",
    "\n",
    "print(f\"\\n6 Governance Indicators:\")\n",
    "for i, col in enumerate(governance_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# verify all governance indicators are present\n",
    "missing_gov = [col for col in governance_cols if col not in main_df.columns]\n",
    "if missing_gov:\n",
    "    print(f\"\\n⚠️  warning: missing governance indicators: {missing_gov}\")\n",
    "else:\n",
    "    print(f\"\\n✓ all 6 governance indicators present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in governance indicators:\n",
      "Series([], dtype: int64)\n",
      "✓ no missing governance indicators - complete coverage for all 266 country-years\n"
     ]
    }
   ],
   "source": [
    "# verify no missing values in governance indicators\n",
    "print(\"Missing values in governance indicators:\")\n",
    "missing_gov = main_df[governance_cols].isnull().sum()\n",
    "print(missing_gov[missing_gov > 0])\n",
    "if missing_gov.sum() == 0:\n",
    "    print(\"✓ no missing governance indicators - complete coverage for all 266 country-years\")\n",
    "else:\n",
    "    print(f\"⚠️  warning: {missing_gov.sum()} missing values in governance indicators\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Governance Indicator Summary Statistics\n",
    "\n",
    "All governance indicators are standardized scores (typically ranging from -2.5 to 2.5), where:\n",
    "- **Positive values** = better governance (lower corruption risk)\n",
    "- **Negative values** = worse governance (higher corruption risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GOVERNANCE INDICATORS - SUMMARY STATISTICS\n",
      "======================================================================\n",
      "                           mean    std    min    max\n",
      "Voice_Accountability      0.353  1.034 -1.618  1.781\n",
      "Political_Stability      -0.011  1.111 -2.609  1.599\n",
      "Government_Effectiveness  0.475  1.274 -1.889  2.317\n",
      "Regulatory_Quality        0.427  1.305 -2.387  2.309\n",
      "Rule_of_Law               0.319  1.385 -2.332  2.101\n",
      "Control_of_Corruption     0.426  1.433 -1.690  2.403\n",
      "\n",
      "======================================================================\n",
      "GOVERNANCE INDICATORS BY RISK CATEGORY\n",
      "======================================================================\n",
      "\n",
      "Voice_Accountability:\n",
      "  Low-risk countries (0):  1.319\n",
      "  High-risk countries (1): -0.349\n",
      "  Difference: -1.667 (high-risk countries have lower scores)\n",
      "\n",
      "Political_Stability:\n",
      "  Low-risk countries (0):  1.107\n",
      "  High-risk countries (1): -0.825\n",
      "  Difference: -1.931 (high-risk countries have lower scores)\n",
      "\n",
      "Government_Effectiveness:\n",
      "  Low-risk countries (0):  1.800\n",
      "  High-risk countries (1): -0.489\n",
      "  Difference: -2.290 (high-risk countries have lower scores)\n",
      "\n",
      "Regulatory_Quality:\n",
      "  Low-risk countries (0):  1.787\n",
      "  High-risk countries (1): -0.561\n",
      "  Difference: -2.348 (high-risk countries have lower scores)\n",
      "\n",
      "Rule_of_Law:\n",
      "  Low-risk countries (0):  1.787\n",
      "  High-risk countries (1): -0.748\n",
      "  Difference: -2.536 (high-risk countries have lower scores)\n",
      "\n",
      "Control_of_Corruption:\n",
      "  Low-risk countries (0):  2.024\n",
      "  High-risk countries (1): -0.736\n",
      "  Difference: -2.760 (high-risk countries have lower scores)\n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics for governance indicators\n",
    "print(\"=\"*70)\n",
    "print(\"GOVERNANCE INDICATORS - SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "gov_stats = main_df[governance_cols].describe().T\n",
    "gov_stats = gov_stats[['mean', 'std', 'min', 'max']]\n",
    "print(gov_stats.round(3))\n",
    "\n",
    "# show distribution by risk category\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GOVERNANCE INDICATORS BY RISK CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "for col in governance_cols:\n",
    "    low_risk_mean = main_df[main_df['corruption_risk'] == 0][col].mean()\n",
    "    high_risk_mean = main_df[main_df['corruption_risk'] == 1][col].mean()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Low-risk countries (0):  {low_risk_mean:.3f}\")\n",
    "    print(f\"  High-risk countries (1): {high_risk_mean:.3f}\")\n",
    "    print(f\"  Difference: {high_risk_mean - low_risk_mean:.3f} (high-risk countries have lower scores)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Governance-Based Labeling Conclusion\n",
    "\n",
    "The corruption_risk labels are created using the \"4-of-6\" flag system:\n",
    "- Each governance indicator below its threshold gets a flag (1)\n",
    "- Countries with 4 or more flags are labeled as high-risk (corruption_risk = 1)\n",
    "- Countries with fewer than 4 flags are labeled as low-risk (corruption_risk = 0)\n",
    "\n",
    "**Key Point**: Governance indicators are the PRIMARY signal because they directly determine the target variable. The machine learning model will learn patterns in these indicators to predict corruption risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GOVERNANCE-BASED LABELING VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Total records: 266\n",
      "High-risk (corruption_risk = 1): 154 (57.9%)\n",
      "Low-risk (corruption_risk = 0): 112 (42.1%)\n",
      "\n",
      "Flag distribution (total_flags column):\n",
      "total_flags\n",
      "0     98\n",
      "1     14\n",
      "6    154\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Governance indicators are the PRIMARY signal for corruption risk\n",
      "  All high-risk countries have 4+ governance flags\n",
      "  All low-risk countries have <4 governance flags\n"
     ]
    }
   ],
   "source": [
    "# verify how governance indicators determine corruption_risk labels\n",
    "print(\"=\"*70)\n",
    "print(\"GOVERNANCE-BASED LABELING VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal records: {len(main_df)}\")\n",
    "print(f\"High-risk (corruption_risk = 1): {(main_df['corruption_risk'] == 1).sum()} ({(main_df['corruption_risk'] == 1).mean():.1%})\")\n",
    "print(f\"Low-risk (corruption_risk = 0): {(main_df['corruption_risk'] == 0).sum()} ({(main_df['corruption_risk'] == 0).mean():.1%})\")\n",
    "\n",
    "# show flag distribution\n",
    "print(f\"\\nFlag distribution (total_flags column):\")\n",
    "print(main_df['total_flags'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\n✓ Governance indicators are the PRIMARY signal for corruption risk\")\n",
    "print(f\"  All high-risk countries have 4+ governance flags\")\n",
    "print(f\"  All low-risk countries have <4 governance flags\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Economic Indicators (Secondary Quantitative Signal)\n",
    "\n",
    "The 5 economic indicators provide **complementary quantitative economic context**. Unlike governance indicators, economic data has some missing values that need to be handled. These indicators help the model understand economic conditions that may correlate with corruption risk, complementing the primary governance signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Load and Verify Economic Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ECONOMIC INDICATORS - DATA COVERAGE\n",
      "======================================================================\n",
      "\n",
      "5 Economic Indicators:\n",
      "  1. GDP_Growth_annual_perc\n",
      "  2. External_Debt_perc_GNI\n",
      "  3. Govt_Expenditure_perc_GDP\n",
      "  4. FDI_Inflows_perc_GDP\n",
      "  5. Poverty_Headcount_Ratio\n",
      "\n",
      "Missing values in economic indicators (before handling):\n",
      "GDP_Growth_annual_perc         9\n",
      "External_Debt_perc_GNI       145\n",
      "Govt_Expenditure_perc_GDP     45\n",
      "FDI_Inflows_perc_GDP           9\n",
      "Poverty_Headcount_Ratio      150\n",
      "dtype: int64\n",
      "\n",
      "total missing values: 358 out of 1330 possible values\n",
      "missing percentage: 26.9%\n",
      "\n",
      "Data coverage per indicator:\n",
      "  GDP_Growth_annual_perc: 96.6% coverage (257/266 records)\n",
      "  External_Debt_perc_GNI: 45.5% coverage (121/266 records)\n",
      "  Govt_Expenditure_perc_GDP: 83.1% coverage (221/266 records)\n",
      "  FDI_Inflows_perc_GDP: 96.6% coverage (257/266 records)\n",
      "  Poverty_Headcount_Ratio: 43.6% coverage (116/266 records)\n"
     ]
    }
   ],
   "source": [
    "# identify the 5 economic indicators\n",
    "economic_cols = [\n",
    "    'GDP_Growth_annual_perc',\n",
    "    'External_Debt_perc_GNI',\n",
    "    'Govt_Expenditure_perc_GDP',\n",
    "    'FDI_Inflows_perc_GDP',\n",
    "    'Poverty_Headcount_Ratio'\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ECONOMIC INDICATORS - DATA COVERAGE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n5 Economic Indicators:\")\n",
    "for i, col in enumerate(economic_cols, 1):\n",
    "    print(f\"  {i}. {col}\")\n",
    "\n",
    "# check missing values before handling\n",
    "print(\"\\nMissing values in economic indicators (before handling):\")\n",
    "missing_econ = main_df[economic_cols].isnull().sum()\n",
    "print(missing_econ[missing_econ > 0])\n",
    "print(f\"\\ntotal missing values: {missing_econ.sum()} out of {len(main_df) * len(economic_cols)} possible values\")\n",
    "print(f\"missing percentage: {missing_econ.sum() / (len(main_df) * len(economic_cols)) * 100:.1f}%\")\n",
    "\n",
    "# show coverage per indicator\n",
    "print(\"\\nData coverage per indicator:\")\n",
    "for col in economic_cols:\n",
    "    coverage = (main_df[col].notna().sum() / len(main_df)) * 100\n",
    "    print(f\"  {col}: {coverage:.1f}% coverage ({main_df[col].notna().sum()}/{len(main_df)} records)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Handle Missing Economic Data\n",
    "\n",
    "Economic data changes slowly over time, so we use forward-fill within each country (carrying the last known value forward). For any remaining missing values, we use the median across all countries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HANDLING MISSING ECONOMIC DATA\n",
      "======================================================================\n",
      "\n",
      "Step 1: Forward-fill within each country (carry last known value forward)\n",
      "  GDP_Growth_annual_perc: filled 9 values via forward-fill\n",
      "  Govt_Expenditure_perc_GDP: filled 27 values via forward-fill\n",
      "  FDI_Inflows_perc_GDP: filled 9 values via forward-fill\n",
      "  Poverty_Headcount_Ratio: filled 88 values via forward-fill\n",
      "\n",
      "Missing values after forward-fill:\n",
      "External_Debt_perc_GNI       145\n",
      "Govt_Expenditure_perc_GDP     18\n",
      "Poverty_Headcount_Ratio       62\n",
      "dtype: int64\n",
      "total remaining: 225\n",
      "\n",
      "Step 2: Fill remaining missing values with median\n",
      "  External_Debt_perc_GNI: filled with median = 37.708\n",
      "  Govt_Expenditure_perc_GDP: filled with median = 25.986\n",
      "  Poverty_Headcount_Ratio: filled with median = 0.500\n",
      "\n",
      "Final check - missing values in economic indicators:\n",
      "GDP_Growth_annual_perc       0\n",
      "External_Debt_perc_GNI       0\n",
      "Govt_Expenditure_perc_GDP    0\n",
      "FDI_Inflows_perc_GDP         0\n",
      "Poverty_Headcount_Ratio      0\n",
      "dtype: int64\n",
      "✓ all economic indicators now have complete coverage\n"
     ]
    }
   ],
   "source": [
    "# create a copy for processing (we'll merge everything later)\n",
    "merged_df = main_df.copy()\n",
    "\n",
    "# forward fill economic indicators within each country\n",
    "# economic data changes slowly, so forward fill is reasonable\n",
    "merged_df = merged_df.sort_values(['Country', 'Year'])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HANDLING MISSING ECONOMIC DATA\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nStep 1: Forward-fill within each country (carry last known value forward)\")\n",
    "\n",
    "for col in economic_cols:\n",
    "    before = merged_df[col].isna().sum()\n",
    "    merged_df[col] = merged_df.groupby('Country')[col].ffill()\n",
    "    after = merged_df[col].isna().sum()\n",
    "    if before > after:\n",
    "        print(f\"  {col}: filled {before - after} values via forward-fill\")\n",
    "\n",
    "print(\"\\nMissing values after forward-fill:\")\n",
    "missing_econ_after = merged_df[economic_cols].isnull().sum()\n",
    "print(missing_econ_after[missing_econ_after > 0])\n",
    "print(f\"total remaining: {missing_econ_after.sum()}\")\n",
    "\n",
    "print(\"\\nStep 2: Fill remaining missing values with median\")\n",
    "for col in economic_cols:\n",
    "    if merged_df[col].isna().any():\n",
    "        median_val = merged_df[col].median()\n",
    "        merged_df[col] = merged_df[col].fillna(median_val)\n",
    "        print(f\"  {col}: filled with median = {median_val:.3f}\")\n",
    "\n",
    "# verify no missing values remain\n",
    "print(\"\\nFinal check - missing values in economic indicators:\")\n",
    "final_missing = merged_df[economic_cols].isnull().sum()\n",
    "print(final_missing)\n",
    "if final_missing.sum() == 0:\n",
    "    print(\"✓ all economic indicators now have complete coverage\")\n",
    "else:\n",
    "    print(f\"⚠️  warning: {final_missing.sum()} missing values remain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Economic Indicator Summary Statistics\n",
    "\n",
    "Economic indicators provide context about economic conditions. They are not the primary signal for corruption risk, but they help the model understand the economic environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ECONOMIC INDICATORS - SUMMARY STATISTICS\n",
      "======================================================================\n",
      "                             mean     std     min      max\n",
      "GDP_Growth_annual_perc      2.612   4.514 -28.759   19.675\n",
      "External_Debt_perc_GNI     52.581  61.909   7.955  420.572\n",
      "Govt_Expenditure_perc_GDP  25.172   8.910   9.783   65.560\n",
      "FDI_Inflows_perc_GDP        3.743   8.296 -32.547   38.943\n",
      "Poverty_Headcount_Ratio     9.750  18.717   0.000   81.600\n",
      "\n",
      "Note: Economic indicators provide complementary context, not the primary signal.\n",
      "They help the model understand economic conditions that may correlate with corruption risk.\n"
     ]
    }
   ],
   "source": [
    "# descriptive statistics for economic indicators\n",
    "print(\"=\"*70)\n",
    "print(\"ECONOMIC INDICATORS - SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "econ_stats = merged_df[economic_cols].describe().T\n",
    "econ_stats = econ_stats[['mean', 'std', 'min', 'max']]\n",
    "print(econ_stats.round(3))\n",
    "\n",
    "print(\"\\nNote: Economic indicators provide complementary context, not the primary signal.\")\n",
    "print(\"They help the model understand economic conditions that may correlate with corruption risk.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Sentiment Analysis (Qualitative Early Warning Signal)\n",
    "\n",
    "Sentiment analysis provides **qualitative data to enrich the model's predictive power** and serves as an **early qualitative warning sign alongside quantitative governance indicators** (as outlined in the theoretical framework). As validated in notebook 04, sentiment captures corruption-related news and reveals transparency patterns. Countries with free press show more negative sentiment (corruption gets exposed), while countries with media suppression show less negative sentiment (corruption is hidden). This qualitative signal complements the quantitative governance and economic indicators.\n",
    "\n",
    "### 4.1: Load Sentiment Scores from Notebook 04 Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SENTIMENT ANALYSIS - DATA COVERAGE\n",
      "======================================================================\n",
      "Sentiment records: 234\n",
      "Countries: 19\n",
      "Year range: 2010 to 2023\n",
      "\n",
      "Coverage comparison:\n",
      "  Main dataset: 266 country-years\n",
      "  Sentiment data: 234 country-years\n",
      "  Missing sentiment: 32 country-years (12.0%)\n",
      "\n",
      "Note: Some country-years don't have corruption-related news articles.\n",
      "This is expected - not every country-year has corruption news coverage.\n"
     ]
    }
   ],
   "source": [
    "# load sentiment scores (validated in notebook 04)\n",
    "sentiment_df = pd.read_csv('data/sentiment/sentiment_scores.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SENTIMENT ANALYSIS - DATA COVERAGE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Sentiment records: {len(sentiment_df)}\")\n",
    "print(f\"Countries: {sentiment_df['country'].nunique()}\")\n",
    "print(f\"Year range: {sentiment_df['year'].min()} to {sentiment_df['year'].max()}\")\n",
    "\n",
    "# check coverage vs main dataset\n",
    "print(f\"\\nCoverage comparison:\")\n",
    "print(f\"  Main dataset: {len(main_df)} country-years\")\n",
    "print(f\"  Sentiment data: {len(sentiment_df)} country-years\")\n",
    "print(f\"  Missing sentiment: {len(main_df) - len(sentiment_df)} country-years ({((len(main_df) - len(sentiment_df)) / len(main_df) * 100):.1f}%)\")\n",
    "\n",
    "print(\"\\nNote: Some country-years don't have corruption-related news articles.\")\n",
    "print(\"This is expected - not every country-year has corruption news coverage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Merge Sentiment with Main Dataset\n",
    "\n",
    "We merge sentiment scores using a left join (keeping all records from the main dataset). Country-years without sentiment data are filled with 0.0 (neutral), representing no corruption-related news coverage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SENTIMENT MERGE RESULTS\n",
      "======================================================================\n",
      "Merged dataset shape: (266, 24)\n",
      "Records with sentiment data: 234\n",
      "Records without sentiment data: 32\n",
      "\n",
      "✓ merge successful: 266 records (expected: 266)\n",
      "\n",
      "After filling missing values with 0.0 (neutral):\n",
      "  Records with original sentiment: 234\n",
      "  Records with neutral (0.0) sentiment: 32\n"
     ]
    }
   ],
   "source": [
    "# merge sentiment scores with main dataset on country and year\n",
    "# use left join to keep all records from main dataset\n",
    "merged_df = merged_df.merge(\n",
    "    sentiment_df,\n",
    "    left_on=['Country', 'Year'],\n",
    "    right_on=['country', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# drop duplicate columns from sentiment dataset\n",
    "merged_df = merged_df.drop(columns=['country', 'year'], errors='ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SENTIMENT MERGE RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "print(f\"Records with sentiment data: {merged_df['sentiment_score'].notna().sum()}\")\n",
    "print(f\"Records without sentiment data: {merged_df['sentiment_score'].isna().sum()}\")\n",
    "\n",
    "# verify we still have all 266 records\n",
    "assert len(merged_df) == len(main_df), \"merge lost records!\"\n",
    "print(f\"\\n✓ merge successful: {len(merged_df)} records (expected: {len(main_df)})\")\n",
    "\n",
    "# fill missing sentiment scores with 0.0 (neutral)\n",
    "# this represents country-years without corruption-related news articles\n",
    "merged_df['sentiment_score'] = merged_df['sentiment_score'].fillna(0.0)\n",
    "merged_df['article_count'] = merged_df['article_count'].fillna(0.0)\n",
    "\n",
    "print(f\"\\nAfter filling missing values with 0.0 (neutral):\")\n",
    "print(f\"  Records with original sentiment: {merged_df[merged_df['article_count'] > 0].shape[0]}\")\n",
    "print(f\"  Records with neutral (0.0) sentiment: {merged_df[merged_df['article_count'] == 0].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Sentiment Summary and Validation\n",
    "\n",
    "As validated in notebook 04:\n",
    "- **Both risk categories show negative sentiment** (corruption news is inherently negative)\n",
    "- **Case studies validated**: Malaysia 1MDB (2013-2015) and Mozambique hidden debt (2013-2016) show negative sentiment\n",
    "- **Sentiment measures transparency/visibility**, not just severity\n",
    "- **Low-risk countries** with free press show more negative sentiment (corruption gets exposed)\n",
    "- **High-risk countries** with media suppression show less negative sentiment (corruption is hidden)\n",
    "\n",
    "**Key Point**: Sentiment is the SMALLEST contributing factor but provides complementary signal about corruption visibility and transparency that enhances governance-based risk assessment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SENTIMENT ANALYSIS - SUMMARY STATISTICS\n",
      "======================================================================\n",
      "\n",
      "Sentiment score statistics:\n",
      "  Mean: -0.0825\n",
      "  Median: -0.0644\n",
      "  Std: 0.0988\n",
      "  Range: [-0.4758, 0.4923]\n",
      "\n",
      "Sentiment by risk category:\n",
      "  Low-risk countries (0):  -0.1004\n",
      "  High-risk countries (1): -0.0694\n",
      "\n",
      "✓ Both categories show negative sentiment (as validated in notebook 04)\n",
      "\n",
      "Note: Sentiment provides qualitative early warning signals that complement\n",
      "the quantitative governance and economic indicators, enriching the model's\n",
      "predictive power by capturing corruption visibility and transparency patterns.\n"
     ]
    }
   ],
   "source": [
    "# sentiment summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"SENTIMENT ANALYSIS - SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nSentiment score statistics:\")\n",
    "print(f\"  Mean: {merged_df['sentiment_score'].mean():.4f}\")\n",
    "print(f\"  Median: {merged_df['sentiment_score'].median():.4f}\")\n",
    "print(f\"  Std: {merged_df['sentiment_score'].std():.4f}\")\n",
    "print(f\"  Range: [{merged_df['sentiment_score'].min():.4f}, {merged_df['sentiment_score'].max():.4f}]\")\n",
    "\n",
    "# show sentiment by risk category (from notebook 04 validation)\n",
    "print(f\"\\nSentiment by risk category:\")\n",
    "low_risk_sentiment = merged_df[merged_df['corruption_risk'] == 0]['sentiment_score'].mean()\n",
    "high_risk_sentiment = merged_df[merged_df['corruption_risk'] == 1]['sentiment_score'].mean()\n",
    "print(f\"  Low-risk countries (0):  {low_risk_sentiment:.4f}\")\n",
    "print(f\"  High-risk countries (1): {high_risk_sentiment:.4f}\")\n",
    "print(f\"\\n✓ Both categories show negative sentiment (as validated in notebook 04)\")\n",
    "\n",
    "print(f\"\\nNote: Sentiment provides qualitative early warning signals that complement\")\n",
    "print(f\"the quantitative governance and economic indicators, enriching the model's\")\n",
    "print(f\"predictive power by capturing corruption visibility and transparency patterns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Sentiment and Transparency Relationship\n",
    "\n",
    "**Key Question**: Does negative sentiment accompany higher transparency? Are they complementary?\n",
    "\n",
    "**Answer**: Yes, they are complementary. This relationship is a key insight from notebook 04:\n",
    "\n",
    "- **Higher transparency (free press)** → More negative sentiment (corruption gets exposed and reported)\n",
    "- **Lower transparency (media suppression)** → Less negative sentiment (corruption is hidden from public view)\n",
    "\n",
    "**Why this matters**: Negative sentiment doesn't just mean \"bad corruption\" - it also means \"corruption is being exposed/reported\", which requires transparency and free press. Countries with higher Voice_Accountability (transparency indicator) can expose corruption more effectively, leading to more negative sentiment in news coverage.\n",
    "\n",
    "This complementary relationship enriches our model: sentiment provides qualitative information about corruption visibility that complements the quantitative governance indicators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SENTIMENT AND TRANSPARENCY RELATIONSHIP\n",
      "======================================================================\n",
      "\n",
      "correlation between sentiment_score and Voice_Accountability: -0.1578\n",
      "  interpretation: negative correlation\n",
      "  higher transparency → more negative sentiment\n",
      "\n",
      "sentiment by transparency quartile:\n",
      "                        count    mean  median\n",
      "transparency_quartile                        \n",
      "Low Transparency (Q1)      67 -0.0632 -0.0433\n",
      "Medium-Low (Q2)            66 -0.0652 -0.0509\n",
      "Medium-High (Q3)           66 -0.1088 -0.1039\n",
      "High Transparency (Q4)     67 -0.0930 -0.0605\n",
      "\n",
      "pattern:\n",
      "  low transparency (Q1):  -0.0632 (less negative)\n",
      "  high transparency (Q4): -0.0930 (more negative)\n",
      "  difference: -0.0298\n",
      "\n",
      "✓ complementary relationship confirmed:\n",
      "  higher transparency → more negative sentiment (corruption gets exposed)\n",
      "  lower transparency → less negative sentiment (corruption is hidden)\n",
      "\n",
      "======================================================================\n",
      "SENTIMENT BY RISK CATEGORY AND TRANSPARENCY\n",
      "======================================================================\n",
      "\n",
      "Low Risk countries:\n",
      "  low transparency:  nan\n",
      "  high transparency: -0.0930\n",
      "  difference: nan\n",
      "\n",
      "High Risk countries:\n",
      "  low transparency:  -0.0632\n",
      "  high transparency: nan\n",
      "  difference: nan\n",
      "\n",
      "✓ sentiment and transparency are complementary:\n",
      "  both low-risk and high-risk countries show more negative sentiment\n",
      "  when transparency is higher (corruption gets exposed and reported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/_s3wzh8j3mbgc971jkb0__nc0000gn/T/ipykernel_12498/1769031455.py:21: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  transparency_sentiment = merged_df.groupby('transparency_quartile')['sentiment_score'].agg([\n"
     ]
    }
   ],
   "source": [
    "# analyze relationship between sentiment and transparency (Voice_Accountability)\n",
    "print(\"=\"*70)\n",
    "print(\"SENTIMENT AND TRANSPARENCY RELATIONSHIP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# calculate correlation between sentiment and Voice_Accountability\n",
    "# negative correlation expected: higher transparency → more negative sentiment\n",
    "correlation = merged_df['sentiment_score'].corr(merged_df['Voice_Accountability'])\n",
    "print(f\"\\ncorrelation between sentiment_score and Voice_Accountability: {correlation:.4f}\")\n",
    "print(f\"  interpretation: {'negative' if correlation < 0 else 'positive'} correlation\")\n",
    "print(f\"  higher transparency → {'more negative' if correlation < 0 else 'less negative'} sentiment\")\n",
    "\n",
    "# analyze by transparency quartiles\n",
    "merged_df['transparency_quartile'] = pd.qcut(\n",
    "    merged_df['Voice_Accountability'], \n",
    "    q=4, \n",
    "    labels=['Low Transparency (Q1)', 'Medium-Low (Q2)', 'Medium-High (Q3)', 'High Transparency (Q4)']\n",
    ")\n",
    "\n",
    "print(f\"\\nsentiment by transparency quartile:\")\n",
    "transparency_sentiment = merged_df.groupby('transparency_quartile')['sentiment_score'].agg([\n",
    "    'count', 'mean', 'median'\n",
    "]).round(4)\n",
    "print(transparency_sentiment)\n",
    "\n",
    "# show pattern\n",
    "print(f\"\\npattern:\")\n",
    "q1_sentiment = merged_df[merged_df['transparency_quartile'] == 'Low Transparency (Q1)']['sentiment_score'].mean()\n",
    "q4_sentiment = merged_df[merged_df['transparency_quartile'] == 'High Transparency (Q4)']['sentiment_score'].mean()\n",
    "print(f\"  low transparency (Q1):  {q1_sentiment:.4f} (less negative)\")\n",
    "print(f\"  high transparency (Q4): {q4_sentiment:.4f} (more negative)\")\n",
    "print(f\"  difference: {q4_sentiment - q1_sentiment:.4f}\")\n",
    "\n",
    "if q4_sentiment < q1_sentiment:\n",
    "    print(f\"\\n✓ complementary relationship confirmed:\")\n",
    "    print(f\"  higher transparency → more negative sentiment (corruption gets exposed)\")\n",
    "    print(f\"  lower transparency → less negative sentiment (corruption is hidden)\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  unexpected pattern - may need further investigation\")\n",
    "\n",
    "# analyze by risk category and transparency\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"SENTIMENT BY RISK CATEGORY AND TRANSPARENCY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for risk_level in [0, 1]:\n",
    "    risk_label = \"Low Risk\" if risk_level == 0 else \"High Risk\"\n",
    "    risk_data = merged_df[merged_df['corruption_risk'] == risk_level]\n",
    "    \n",
    "    low_trans = risk_data[risk_data['transparency_quartile'] == 'Low Transparency (Q1)']['sentiment_score'].mean()\n",
    "    high_trans = risk_data[risk_data['transparency_quartile'] == 'High Transparency (Q4)']['sentiment_score'].mean()\n",
    "    \n",
    "    print(f\"\\n{risk_label} countries:\")\n",
    "    print(f\"  low transparency:  {low_trans:.4f}\")\n",
    "    print(f\"  high transparency: {high_trans:.4f}\")\n",
    "    print(f\"  difference: {high_trans - low_trans:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ sentiment and transparency are complementary:\")\n",
    "print(f\"  both low-risk and high-risk countries show more negative sentiment\")\n",
    "print(f\"  when transparency is higher (corruption gets exposed and reported)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Combine All Features\n",
    "\n",
    "Now we combine all three data sources into a single feature set for machine learning model training.\n",
    "\n",
    "### 5.1: Define Final Feature Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL FEATURE SET\n",
      "======================================================================\n",
      "\n",
      "Total features: 12\n",
      "  Governance (primary quantitative signal): 6 features\n",
      "  Economic (secondary quantitative signal): 5 features\n",
      "  Sentiment (qualitative early warning signal): 1 feature\n",
      "\n",
      "Complete feature list:\n",
      "   1. Voice_Accountability           (Governance)\n",
      "   2. Political_Stability            (Governance)\n",
      "   3. Government_Effectiveness       (Governance)\n",
      "   4. Regulatory_Quality             (Governance)\n",
      "   5. Rule_of_Law                    (Governance)\n",
      "   6. Control_of_Corruption          (Governance)\n",
      "   7. GDP_Growth_annual_perc         (Economic)\n",
      "   8. External_Debt_perc_GNI         (Economic)\n",
      "   9. Govt_Expenditure_perc_GDP      (Economic)\n",
      "  10. FDI_Inflows_perc_GDP           (Economic)\n",
      "  11. Poverty_Headcount_Ratio        (Economic)\n",
      "  12. sentiment_score                (Sentiment)\n",
      "\n",
      "✓ all 12 features present in dataset\n"
     ]
    }
   ],
   "source": [
    "# define final feature set (12 features total)\n",
    "governance_features = [\n",
    "    'Voice_Accountability',\n",
    "    'Political_Stability',\n",
    "    'Government_Effectiveness',\n",
    "    'Regulatory_Quality',\n",
    "    'Rule_of_Law',\n",
    "    'Control_of_Corruption'\n",
    "]\n",
    "\n",
    "economic_features = [\n",
    "    'GDP_Growth_annual_perc',\n",
    "    'External_Debt_perc_GNI',\n",
    "    'Govt_Expenditure_perc_GDP',\n",
    "    'FDI_Inflows_perc_GDP',\n",
    "    'Poverty_Headcount_Ratio'\n",
    "]\n",
    "\n",
    "sentiment_features = ['sentiment_score']\n",
    "\n",
    "# combine all features\n",
    "feature_columns = governance_features + economic_features + sentiment_features\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL FEATURE SET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal features: {len(feature_columns)}\")\n",
    "print(f\"  Governance (primary quantitative signal): {len(governance_features)} features\")\n",
    "print(f\"  Economic (secondary quantitative signal): {len(economic_features)} features\")\n",
    "print(f\"  Sentiment (qualitative early warning signal): {len(sentiment_features)} feature\")\n",
    "\n",
    "print(f\"\\nComplete feature list:\")\n",
    "for i, feature in enumerate(feature_columns, 1):\n",
    "    category = \"Governance\" if feature in governance_features else \\\n",
    "               \"Economic\" if feature in economic_features else \"Sentiment\"\n",
    "    print(f\"  {i:2d}. {feature:30s} ({category})\")\n",
    "\n",
    "# verify all features exist in dataset\n",
    "missing_features = [f for f in feature_columns if f not in merged_df.columns]\n",
    "if missing_features:\n",
    "    print(f\"\\n⚠️  warning: missing features: {missing_features}\")\n",
    "else:\n",
    "    print(f\"\\n✓ all {len(feature_columns)} features present in dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Extract Target Variable\n",
    "\n",
    "The target variable (corruption_risk) is binary (0 = low risk, 1 = high risk) and is based on the governance indicators using the \"4-of-6\" flag system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE MATRIX AND TARGET VARIABLE\n",
      "======================================================================\n",
      "\n",
      "Feature matrix (X) shape: (266, 12)\n",
      "Target vector (y) shape: (266,)\n",
      "\n",
      "Target distribution:\n",
      "corruption_risk\n",
      "1    154\n",
      "0    112\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution (%):\n",
      "corruption_risk\n",
      "1    0.578947\n",
      "0    0.421053\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values check:\n",
      "  Feature matrix (X): 0 missing values\n",
      "  Target vector (y): 0 missing values\n",
      "✓ no missing values in feature matrix or target\n"
     ]
    }
   ],
   "source": [
    "# extract feature matrix\n",
    "X = merged_df[feature_columns].copy()\n",
    "\n",
    "# extract target variable\n",
    "y = merged_df['corruption_risk'].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE MATRIX AND TARGET VARIABLE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFeature matrix (X) shape: {X.shape}\")\n",
    "print(f\"Target vector (y) shape: {y.shape}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nTarget distribution (%):\")\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# verify no missing values\n",
    "print(f\"\\nMissing values check:\")\n",
    "print(f\"  Feature matrix (X): {X.isnull().sum().sum()} missing values\")\n",
    "print(f\"  Target vector (y): {y.isnull().sum()} missing values\")\n",
    "\n",
    "if X.isnull().sum().sum() == 0 and y.isnull().sum() == 0:\n",
    "    print(\"✓ no missing values in feature matrix or target\")\n",
    "else:\n",
    "    print(\"⚠️  warning: missing values detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Final Data Quality Checks\n",
    "\n",
    "Before creating train/test splits, we verify data quality: no duplicates, correct year range, correct country count, and reasonable feature ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ no duplicate country-year combinations\n",
      "\n",
      "year range: 2010 to 2023\n",
      "expected: 2010 to 2023\n",
      "\n",
      "countries: 19\n",
      "expected: 19\n",
      "\n",
      "country list:\n",
      "['Angola', 'Australia', 'Brazil', 'Canada', 'Denmark', 'Germany', 'India', 'Iraq', 'Malaysia', 'Mozambique', 'New Zealand', 'Norway', 'Philippines', 'Singapore', 'South Africa', 'Switzerland', 'Ukraine', 'Venezuela', 'Zimbabwe']\n",
      "\n",
      "======================================================================\n",
      "FEATURE RANGES VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Voice_Accountability:\n",
      "  range: [-1.618, 1.781]\n",
      "  mean: 0.353, std: 1.034\n",
      "\n",
      "Political_Stability:\n",
      "  range: [-2.609, 1.599]\n",
      "  mean: -0.011, std: 1.111\n",
      "\n",
      "Government_Effectiveness:\n",
      "  range: [-1.889, 2.317]\n",
      "  mean: 0.475, std: 1.274\n",
      "\n",
      "Regulatory_Quality:\n",
      "  range: [-2.387, 2.309]\n",
      "  mean: 0.427, std: 1.305\n",
      "\n",
      "Rule_of_Law:\n",
      "  range: [-2.332, 2.101]\n",
      "  mean: 0.319, std: 1.385\n",
      "\n",
      "Control_of_Corruption:\n",
      "  range: [-1.690, 2.403]\n",
      "  mean: 0.426, std: 1.433\n",
      "\n",
      "GDP_Growth_annual_perc:\n",
      "  range: [-28.759, 19.675]\n",
      "  mean: 2.612, std: 4.514\n",
      "\n",
      "External_Debt_perc_GNI:\n",
      "  range: [7.955, 420.572]\n",
      "  mean: 52.581, std: 61.909\n",
      "\n",
      "Govt_Expenditure_perc_GDP:\n",
      "  range: [9.783, 65.560]\n",
      "  mean: 25.172, std: 8.910\n",
      "\n",
      "FDI_Inflows_perc_GDP:\n",
      "  range: [-32.547, 38.943]\n",
      "  mean: 3.743, std: 8.296\n",
      "\n",
      "Poverty_Headcount_Ratio:\n",
      "  range: [0.000, 81.600]\n",
      "  mean: 9.750, std: 18.717\n",
      "\n",
      "sentiment_score:\n",
      "  range: [-0.476, 0.492]\n",
      "  mean: -0.082, std: 0.099\n",
      "\n",
      "✓ all feature ranges are reasonable\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate country-year combinations\n",
    "duplicates = merged_df.duplicated(subset=['Country', 'Year'], keep=False)\n",
    "if duplicates.any():\n",
    "    print(f\"⚠️  warning: {duplicates.sum()} duplicate country-year combinations found\")\n",
    "    print(merged_df[duplicates][['Country', 'Year']])\n",
    "else:\n",
    "    print(\"✓ no duplicate country-year combinations\")\n",
    "\n",
    "# verify year range\n",
    "year_numeric = pd.to_numeric(merged_df['Year'], errors='coerce')\n",
    "print(f\"\\nyear range: {int(year_numeric.min())} to {int(year_numeric.max())}\")\n",
    "print(f\"expected: 2010 to 2023\")\n",
    "\n",
    "# verify country count\n",
    "print(f\"\\ncountries: {merged_df['Country'].nunique()}\")\n",
    "print(f\"expected: 19\")\n",
    "print(f\"\\ncountry list:\")\n",
    "print(sorted(merged_df['Country'].unique()))\n",
    "\n",
    "# verify feature ranges are reasonable\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE RANGES VERIFICATION\")\n",
    "print(\"=\"*70)\n",
    "for col in feature_columns:\n",
    "    col_min = X[col].min()\n",
    "    col_max = X[col].max()\n",
    "    col_mean = X[col].mean()\n",
    "    col_std = X[col].std()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  range: [{col_min:.3f}, {col_max:.3f}]\")\n",
    "    print(f\"  mean: {col_mean:.3f}, std: {col_std:.3f}\")\n",
    "\n",
    "print(\"\\n✓ all feature ranges are reasonable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Train-Test Split\n",
    "\n",
    "We create a stratified train-test split (80/20) to maintain class balance in both training and testing sets. This ensures the model sees a representative sample of both high-risk and low-risk cases during training.\n",
    "\n",
    "### 6.1: Stratified Split (80/20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAIN-TEST SPLIT RESULTS\n",
      "======================================================================\n",
      "\n",
      "Train set shape: (212, 12)\n",
      "Test set shape: (54, 12)\n",
      "\n",
      "Train set class distribution:\n",
      "corruption_risk\n",
      "1    123\n",
      "0     89\n",
      "Name: count, dtype: int64\n",
      "Train set class distribution (%):\n",
      "corruption_risk\n",
      "1    0.580189\n",
      "0    0.419811\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test set class distribution:\n",
      "corruption_risk\n",
      "1    31\n",
      "0    23\n",
      "Name: count, dtype: int64\n",
      "Test set class distribution (%):\n",
      "corruption_risk\n",
      "1    0.574074\n",
      "0    0.425926\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class balance check:\n",
      "  Overall: 0.579\n",
      "  Train: 0.580\n",
      "  Test: 0.574\n",
      "  Difference: 0.006\n",
      "✓ class balance maintained in train/test splits\n"
     ]
    }
   ],
   "source": [
    "# create stratified train-test split (80/20)\n",
    "# stratified to maintain class balance in both splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAIN-TEST SPLIT RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTrain set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "\n",
    "print(f\"\\nTrain set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Train set class distribution (%):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Test set class distribution (%):\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# verify class balance is maintained\n",
    "train_balance = y_train.mean()\n",
    "test_balance = y_test.mean()\n",
    "overall_balance = y.mean()\n",
    "\n",
    "print(f\"\\nClass balance check:\")\n",
    "print(f\"  Overall: {overall_balance:.3f}\")\n",
    "print(f\"  Train: {train_balance:.3f}\")\n",
    "print(f\"  Test: {test_balance:.3f}\")\n",
    "print(f\"  Difference: {abs(train_balance - test_balance):.3f}\")\n",
    "\n",
    "if abs(train_balance - test_balance) < 0.05:\n",
    "    print(\"✓ class balance maintained in train/test splits\")\n",
    "else:\n",
    "    print(\"⚠️  warning: significant class imbalance between train and test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2: Save Prepared Datasets\n",
    "\n",
    "We save the prepared datasets for model training and the feature names list for model loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ saved: data/processed/final_training_data.csv\n",
      "  shape: (266, 25)\n",
      "✓ saved: data/processed/train_set.csv\n",
      "  shape: (212, 13)\n",
      "✓ saved: data/processed/test_set.csv\n",
      "  shape: (54, 13)\n",
      "✓ saved: models/feature_names.txt\n",
      "  features: 12\n"
     ]
    }
   ],
   "source": [
    "# create directories if they don't exist\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# save full dataset with all features\n",
    "final_df = merged_df.copy()\n",
    "final_df.to_csv('data/processed/final_training_data.csv', index=False)\n",
    "print(\"✓ saved: data/processed/final_training_data.csv\")\n",
    "print(f\"  shape: {final_df.shape}\")\n",
    "\n",
    "# save training set (features + target)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "train_df.to_csv('data/processed/train_set.csv', index=False)\n",
    "print(\"✓ saved: data/processed/train_set.csv\")\n",
    "print(f\"  shape: {train_df.shape}\")\n",
    "\n",
    "# save test set (features + target)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df.to_csv('data/processed/test_set.csv', index=False)\n",
    "print(\"✓ saved: data/processed/test_set.csv\")\n",
    "print(f\"  shape: {test_df.shape}\")\n",
    "\n",
    "# save feature names list for model loading\n",
    "with open('models/feature_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_columns))\n",
    "\n",
    "print(\"✓ saved: models/feature_names.txt\")\n",
    "print(f\"  features: {len(feature_columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Summary & Validation\n",
    "\n",
    "Final summary of the prepared dataset and validation that case study countries are present.\n",
    "\n",
    "### 7.1: Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATASET SUMMARY\n",
      "======================================================================\n",
      "total records: 266\n",
      "countries: 19\n",
      "years: 2010 - 2023\n",
      "features: 12\n",
      "\n",
      "class distribution:\n",
      "  low risk (0): 112 (42.1%)\n",
      "  high risk (1): 154 (57.9%)\n",
      "\n",
      "train/test split:\n",
      "  train: 212 records (79.7%)\n",
      "  test: 54 records (20.3%)\n"
     ]
    }
   ],
   "source": [
    "# dataset summary\n",
    "print(\"=\"*70)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"total records: {len(merged_df)}\")\n",
    "print(f\"countries: {merged_df['Country'].nunique()}\")\n",
    "print(f\"years: {int(year_numeric.min())} - {int(year_numeric.max())}\")\n",
    "print(f\"features: {len(feature_columns)}\")\n",
    "print(f\"\\nclass distribution:\")\n",
    "print(f\"  low risk (0): {(y == 0).sum()} ({(y == 0).mean():.1%})\")\n",
    "print(f\"  high risk (1): {(y == 1).sum()} ({(y == 1).mean():.1%})\")\n",
    "print(f\"\\ntrain/test split:\")\n",
    "print(f\"  train: {len(X_train)} records ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"  test: {len(X_test)} records ({len(X_test)/len(X):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2: Feature Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE SUMMARY STATISTICS\n",
      "======================================================================\n",
      "                             mean     std     min      max\n",
      "Voice_Accountability        0.353   1.034  -1.618    1.781\n",
      "Political_Stability        -0.011   1.111  -2.609    1.599\n",
      "Government_Effectiveness    0.475   1.274  -1.889    2.317\n",
      "Regulatory_Quality          0.427   1.305  -2.387    2.309\n",
      "Rule_of_Law                 0.319   1.385  -2.332    2.101\n",
      "Control_of_Corruption       0.426   1.433  -1.690    2.403\n",
      "GDP_Growth_annual_perc      2.612   4.514 -28.759   19.675\n",
      "External_Debt_perc_GNI     52.581  61.909   7.955  420.572\n",
      "Govt_Expenditure_perc_GDP  25.172   8.910   9.783   65.560\n",
      "FDI_Inflows_perc_GDP        3.743   8.296 -32.547   38.943\n",
      "Poverty_Headcount_Ratio     9.750  18.717   0.000   81.600\n",
      "sentiment_score            -0.082   0.099  -0.476    0.492\n"
     ]
    }
   ],
   "source": [
    "# feature summary statistics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "feature_summary = X.describe().T\n",
    "feature_summary = feature_summary[['mean', 'std', 'min', 'max']]\n",
    "print(feature_summary.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3: Case Study Validation\n",
    "\n",
    "Verify that our case study countries (Malaysia 1MDB, Mozambique hidden debt, Canada control) are present in the dataset with correct labels and sentiment scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASE STUDY VALIDATION\n",
      "======================================================================\n",
      "\n",
      "malaysia 1mdb scandal period (2013-2015):\n",
      "  records: 3\n",
      "  corruption_risk: [1]\n",
      "  sentiment_score: -0.1772\n",
      "  ✓ present in dataset\n",
      "\n",
      "mozambique hidden debt crisis (2013-2016):\n",
      "  records: 4\n",
      "  corruption_risk: [1]\n",
      "  sentiment_score: 0.0030\n",
      "  ✓ present in dataset\n",
      "\n",
      "canada (control country):\n",
      "  records: 14\n",
      "  corruption_risk: [0]\n",
      "  high-risk years: 0/14\n",
      "  ✓ present in dataset\n",
      "\n",
      "======================================================================\n",
      "✓ DATA PREPARATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "The dataset is now ready for machine learning model training.\n",
      "All features are clean, complete, and properly organized.\n"
     ]
    }
   ],
   "source": [
    "# validate case studies are present\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASE STUDY VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# malaysia 1mdb scandal (2013-2015)\n",
    "malaysia_scandal = merged_df[\n",
    "    (merged_df['Country'] == 'Malaysia') & \n",
    "    (merged_df['Year'].between(2013, 2015))\n",
    "]\n",
    "\n",
    "if len(malaysia_scandal) > 0:\n",
    "    print(f\"\\nmalaysia 1mdb scandal period (2013-2015):\")\n",
    "    print(f\"  records: {len(malaysia_scandal)}\")\n",
    "    print(f\"  corruption_risk: {malaysia_scandal['corruption_risk'].unique()}\")\n",
    "    print(f\"  sentiment_score: {malaysia_scandal['sentiment_score'].mean():.4f}\")\n",
    "    print(\"  ✓ present in dataset\")\n",
    "else:\n",
    "    print(\"\\n⚠️  malaysia 2013-2015 not found\")\n",
    "\n",
    "# mozambique hidden debt crisis (2013-2016)\n",
    "mozambique_scandal = merged_df[\n",
    "    (merged_df['Country'] == 'Mozambique') & \n",
    "    (merged_df['Year'].between(2013, 2016))\n",
    "]\n",
    "\n",
    "if len(mozambique_scandal) > 0:\n",
    "    print(f\"\\nmozambique hidden debt crisis (2013-2016):\")\n",
    "    print(f\"  records: {len(mozambique_scandal)}\")\n",
    "    print(f\"  corruption_risk: {mozambique_scandal['corruption_risk'].unique()}\")\n",
    "    print(f\"  sentiment_score: {mozambique_scandal['sentiment_score'].mean():.4f}\")\n",
    "    print(\"  ✓ present in dataset\")\n",
    "else:\n",
    "    print(\"\\n⚠️  mozambique 2013-2016 not found\")\n",
    "\n",
    "# canada (control country)\n",
    "canada = merged_df[merged_df['Country'] == 'Canada']\n",
    "if len(canada) > 0:\n",
    "    print(f\"\\ncanada (control country):\")\n",
    "    print(f\"  records: {len(canada)}\")\n",
    "    print(f\"  corruption_risk: {canada['corruption_risk'].unique()}\")\n",
    "    print(f\"  high-risk years: {canada['corruption_risk'].sum()}/{len(canada)}\")\n",
    "    print(\"  ✓ present in dataset\")\n",
    "else:\n",
    "    print(\"\\n⚠️  canada not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThe dataset is now ready for machine learning model training.\")\n",
    "print(\"All features are clean, complete, and properly organized.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
